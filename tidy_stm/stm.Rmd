---
title: "stm"
author: "Chris Beeley"
date: "7 January 2019"
output: html_document
---

```{r setup, include=FALSE}

# from https://juliasilge.com/blog/evaluating-stm/

knitr::opts_chunk$set(echo = FALSE, warning = FALSE)

library(tidyverse)
library(tidytext)
library(stm)
library(quanteda)
library(drlib)
library(ggthemes)
library(scales)

load("../cleanData.Rdata")
# load("cleanData.Rdata")

# remove the extraneous columns

use_data <- use_data %>% 
  sample_frac(.1) %>%
  # sample_n(1000) %>%
  select(comment, Improve)

tidy_stm <- use_data %>%
  unnest_tokens(word, Improve) %>%
  anti_join(stop_words)

tidy_sparse <- tidy_stm %>%
  count(comment, word, sort = TRUE) %>%
  cast_sparse(comment, word, n)

```

## Basic topic model

K = 40

### Beta

```{r}

topic_model <- stm(tidy_sparse, K = 40, 
                   verbose = FALSE, init.type = "Spectral")

td_beta <- tidy(topic_model)

td_beta %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  mutate(topic = paste0("Topic ", topic),
         term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = as.factor(topic))) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_y") +
  coord_flip() +
  scale_x_reordered() +
  labs(x = NULL, y = expression(beta),
       title = "Highest word probabilities for each topic",
       subtitle = "Different words are associated with different topics")

```

### Gamma

```{r}

lda_gamma <- tidy(topic_model, matrix = "gamma", document_names = rownames(tidy_sparse))

ggplot(lda_gamma, aes(gamma, fill = as.factor(topic))) +
  geom_histogram(show.legend = FALSE) +
  facet_wrap(~ topic, ncol = 4) +
  scale_y_log10() +
  labs(title = "Distribution of probability for each topic",
       y = "Number of documents", x = expression(gamma))

```

### Find documents with high gamma

```{r, results="asis"}

gamma_comments <- lda_gamma %>% 
  group_by(topic) %>% 
  top_n(5, gamma) %>% 
  left_join(
    use_data %>% mutate(comment = as.character(comment)), 
    by = c("document" = "comment")
  ) %>% 
  arrange(topic)

invisible(
  walk(unique(gamma_comments$topic), function(x){
    
    each_topic <- gamma_comments %>% 
      filter(topic == x) %>% 
      pull(Improve) 
    
    cat("<h3>Topic: ", x, "</h3>")
    
    cat(paste("<p>", each_topic, "</p>"))
  })
)

```

## Run several

```{r}

library(furrr)
plan(multiprocess)

system.time({
  many_models <- data_frame(K = c(20, 40, 50, 60, 70, 80, 100)) %>%
  # many_models <- data_frame(K = c(20, 60, 100)) %>%
  mutate(topic_model = future_map(K, ~stm(tidy_sparse, K = .,
                                          verbose = FALSE)))
})

many_models <- data_frame(K = c(20, 60, 100)) %>%
  mutate(topic_model = future_map(K, ~stm(tidy_sparse, K = .,
                                          verbose = FALSE)))

# many_models <- data_frame(K = c(20, 40, 50, 60, 70, 80, 100)) %>%
# many_models <- data_frame(K = c(10, 15, 25, 30, 35, 45, 55, 65, 75, 85, 90, 95, 150, 200)) %>%
#   mutate(topic_model = map(K, ~stm(tidy_sparse, K = .,
#                                           verbose = FALSE)))

heldout <- make.heldout(tidy_sparse)

k_result <- many_models %>%
  mutate(exclusivity = map(topic_model, exclusivity),
         semantic_coherence = map(topic_model, semanticCoherence, tidy_sparse),
         eval_heldout = map(topic_model, eval.heldout, heldout$missing),
         residual = map(topic_model, checkResiduals, tidy_sparse),
         bound =  map_dbl(topic_model, function(x) max(x$convergence$bound)),
         lfact = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
         lbound = bound + lfact,
         iterations = map_dbl(topic_model, function(x) length(x$convergence$bound)))

k_result

k_result %>%
  transmute(K,
            `Lower bound` = lbound,
            Residuals = map_dbl(residual, "dispersion"),
            `Semantic coherence` = map_dbl(semantic_coherence, mean),
            `Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")) %>%
  gather(Metric, Value, -K) %>%
  ggplot(aes(K, Value, color = Metric)) +
  geom_line(size = 1.5, alpha = 0.7, show.legend = FALSE) +
  facet_wrap(~Metric, scales = "free_y") +
  labs(x = "K (number of topics)",
       y = NULL,
       title = "Model diagnostics by number of topics",
       subtitle = "These diagnostics indicate that a good number of topics would be around 50")

k_result %>%
  select(K, exclusivity, semantic_coherence) %>%
  filter(K %in% c(10, 30, 45, 65, 90, 150, 200)) %>%
  unnest() %>%
  mutate(K = as.factor(K)) %>%
  ggplot(aes(semantic_coherence, exclusivity, color = K)) +
  geom_point(size = 2, alpha = 0.7) +
  labs(x = "Semantic coherence",
       y = "Exclusivity",
       title = "Comparing exclusivity and semantic coherence",
       subtitle = "Models with fewer topics have higher semantic coherence for more topics, but lower exclusivity")

save(list = ls(), file = "tidy_stm/savedata3.Rdata")

```

## All results

```{r}

all_results = rbind(l_result, k_result)

all_results %>%
  transmute(K,
            `Lower bound` = lbound,
            Residuals = map_dbl(residual, "dispersion"),
            `Semantic coherence` = map_dbl(semantic_coherence, mean),
            `Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")) %>%
  gather(Metric, Value, -K) %>%
  ggplot(aes(K, Value, color = Metric)) +
  geom_line(size = 1.5, alpha = 0.7, show.legend = FALSE) +
  facet_wrap(~Metric, scales = "free_y") +
  labs(x = "K (number of topics)",
       y = NULL,
       title = "Model diagnostics by number of topics",
       subtitle = "These diagnostics indicate that a good number of topics would be around 50")

```

## 50 topics

```{r}

topic_model <- k_result %>% 
  filter(K == 50) %>% 
  pull(topic_model) %>% 
  .[[1]]

topic_model

td_beta <- tidy(topic_model)

td_beta %>% slice(50:100)

td_gamma <- tidy(topic_model, matrix = "gamma",
                 document_names = rownames(tidy_sparse))

td_gamma

top_terms <- td_beta %>%
  arrange(beta) %>%
  group_by(topic) %>%
  top_n(7, beta) %>%
  arrange(-beta) %>%
  select(topic, term) %>%
  summarise(terms = list(term)) %>%
  mutate(terms = map(terms, paste, collapse = ", ")) %>% 
  unnest()

gamma_terms <- td_gamma %>%
  group_by(topic) %>%
  summarise(gamma = mean(gamma)) %>%
  arrange(desc(gamma)) %>%
  left_join(top_terms, by = "topic") %>%
  mutate(topic = paste0("Topic ", topic),
         topic = reorder(topic, gamma))

gamma_terms %>%
  top_n(20, gamma) %>%
  ggplot(aes(topic, gamma, label = terms, fill = topic)) +
  geom_col(show.legend = FALSE) +
  geom_text(hjust = 0, nudge_y = 0.0005, size = 3,
            family = "IBMPlexSans") +
  coord_flip() +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0, 0.09),
                     labels = percent_format()) +
  theme_tufte(base_family = "IBMPlexSans", ticks = FALSE) +
  theme(plot.title = element_text(size = 16,
                                  family="IBMPlexSans-Bold"),
        plot.subtitle = element_text(size = 13)) +
  labs(x = NULL, y = expression(gamma),
       title = "Top 20 topics by prevalence",
       subtitle = "With the top words that contribute to each topic")
```

