{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227 ms ± 35.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d275567fd9e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'df = pd.read_csv(\"for_gensim.csv\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"for_gensim.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by date\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "mask = (df['Date'] > \"2017-01-01\") & (df['Date'] <= \"2018-12-31\")\n",
    "\n",
    "df_2018 = df.loc[mask]\n",
    "len(df_2018)\n",
    "\n",
    "comments = df[\"Improve\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = comments.apply(lambda x: x.split()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the docs\n",
    "tokenized_list = [simple_preprocess(doc) for doc in comments]\n",
    "\n",
    "# Create the Corpus\n",
    "mydict = corpora.Dictionary()\n",
    "mycorpus = [mydict.doc2bow(doc, allow_update=True) for doc in tokenized_list]\n",
    "# pprint(mycorpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec(description, min_count = 0, workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(['staff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast-text\n",
    "\n",
    "# from gensim.test.utils import common_texts\n",
    "# from gensim.models import FastText\n",
    "# model2 = FastText(description, size=4, window=3, min_count=1, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.wv.most_similar(['treatment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "# Two parts to the answer: how to get the word labels, and how to plot the labels on a scatterplot.\n",
    "\n",
    "# Word labels in gensim's word2vec\n",
    "\n",
    "# model.wv.vocab is a dict of {word: object of numeric vector}. To load the data into X for t-SNE, I made one change.\n",
    "\n",
    "vocab = list(model.wv.vocab)\n",
    "X = model[vocab]\n",
    "\n",
    "# This accomplishes two things: (1) it gets you a standalone vocab list for the final dataframe to plot, and (2) when you index model, you can be sure that you know the order of the words.\n",
    "\n",
    "# Proceed as before with\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# Now let's put X_tsne together with the vocab list. This is easy with pandas, so import pandas as pd if you don't have that yet.\n",
    "\n",
    "df = pd.DataFrame(X_tsne, index=vocab, columns=['x', 'y'])\n",
    "\n",
    "# The vocab words are the indices of the dataframe now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bokeh plots\n",
    "\n",
    "from bokeh.plotting import show, figure, save, output_file\n",
    "\n",
    "output_file(\"first_plot.html\")\n",
    "\n",
    "_ = df.plot.scatter('x', 'y', figsize=(12,12), marker='.', s=10, alpha=0.2)\n",
    "\n",
    "subset_df = df.sample(n=1000)\n",
    "\n",
    "p = figure(plot_width=800, plot_height=800)\n",
    "_ = p.text(x=subset_df.x, y=subset_df.y, text=subset_df.index)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
